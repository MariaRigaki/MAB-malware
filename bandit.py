from utils import *
import random
import pefile
import mmap
import copy
import hashlib
from scipy.stats import beta
import pexpect
import string
from manipulate2 import *
import json
import requests

rewriter_scan_folder = Utils.get_rewriter_scan_folder()
minimizer_scan_folder = Utils.get_minimizer_scan_folder()

copy_tmp_folder = 'output/copy_tmp/'

rewriter_output_folder = 'output/rewriter_output/'
minimizer_output_folder = 'output/minimizer_output/'

evasive_folder = Utils.get_evasive_folder()
minimal_folder = Utils.get_minimal_folder()
functional_folder = Utils.get_functional_folder()

random.seed(10)

os.system('mkdir -p log/')
logger_rew = Utils.setup_logger('rewriter', 'log/rewriter.log')
logger_min = Utils.setup_logger('minimizer', 'log/minimizer.log')

class Arm:
    def __init__(self, idx):
        self.idx = idx
        self.action = None
        self.content = None
        self.name = None
        self.list_reward = []
        self.n_play = 0

    def update_name(self):
        self.name = self.action

    def pull(self, sample):
        logger_rew.info('pull Arm %s (%d)' %(self.name, self.idx))

        return self.transfer(sample.current_exe_path, rewriter_output_folder)

    def transfer(self, input_path, output_folder):
        raise Exception ('Not Implemented')

    def estimated_probas(self):
        raise NotImplementedError

    def get_output_path(self, folder, input_path):
        return folder + os.path.basename(input_path) + '.' + self.action

    def get_overlay_size(self, sample_path):
        file_size = os.path.getsize(sample_path)
        pe = self.try_parse_pe(sample_path)
        if pe == None:
            logger_rew.info('action fail, no change')
            return 0
        overlay_offset = pe.get_overlay_data_start_offset()
        overlay_size = 0
        if overlay_offset != None:
            overlay_size = file_size - overlay_offset
        return overlay_size

    def try_parse_pe(self, sample_path):
        try:
            pe = pefile.PE(sample_path)
            return pe
        except Exception as e:
            logger_rew.info('pefile parse fail')
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logger_rew.error('%s %s:%s cannot parse pe' %(exc_type, fname, exc_tb.tb_lineno))

    def get_available_size_safe(self, pe, section_idx):
        target_section = pe.sections[section_idx]
    
        if section_idx < len(pe.sections) - 1:
            available_size = (pe.sections[section_idx+1].PointerToRawData - target_section.PointerToRawData) - target_section.Misc_VirtualSize
        else:           # the last section
            overlay_offset = pe.get_overlay_data_start_offset()
            if overlay_offset != None:      # pe has overlay data, the last section
                available_size = (overlay_offset - target_section.PointerToRawData) - target_section.Misc_VirtualSize
            else:       # no overlay data, the last section
                available_size = self.get_available_size(pe, section_idx)
    
        if available_size > 0x1000 or available_size < 0:
            available_size = 0
        return available_size

    def get_available_size(self, pe, section_idx):
        target_section = pe.sections[section_idx]
        available_size = target_section.SizeOfRawData - target_section.Misc_VirtualSize
        if available_size < 0:
            available_size = 0
        return available_size

    def print_section_names(self, pe):
        logger_rew.info(self.get_section_name_list(pe))

    def get_section_name_list(self, pe):
        return [str(section.Name.split(b'\0',1)[0]).split('\'')[1] for section in pe.sections]

    def zero_out_file_content(self, file_path, offset, segment_size):
        content = ('\x00'*(segment_size)).encode()
    
        fp_in = open(file_path, 'rb')
        file_content = fp_in.read()
        #logger_rew.info(len(file_content))
        fp_in.close()
    
        fp_out = open(file_path, 'wb')
        fp_out.write(file_content[:offset])
        fp_out.write(content)
        fp_out.write(file_content[offset + len(content):])
        fp_out.close()
    
    def align(self, val_to_align, alignment):
        return (int((val_to_align + alignment - 1) / alignment)) * alignment

class ArmOA(Arm):
    def __init__(self, idx, content_manager=None, content=None):
        super().__init__(idx)
        self.content_manager = content_manager
        self.content = content
        #if content and len(content) == 1:
        #    self.action = 'OA1'
        #else:
        self.action = 'OA'
        self.update_name()

    def update_name(self):
        if self.content == None:
            self.name = 'OA+Rand'
        elif len(self.content) == 1:
            self.name = 'OA+1'
        else:
            self.name = 'OA+' + hashlib.md5(self.content).hexdigest()[:8]

    def set_content(self, content):
        self.content = content
        if len(content) == 1:
            self.action = 'OA1'
        self.update_name()

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        Utils.copy_file(input_path, output_path)
        if self.content == None:
            logger_rew.info('generating new random content')
            _, _, self.content = self.content_manager.get_an_unused_content()
        logger_rew.info('using arm idx: %d, len content: %d' %(self.idx, len(self.content)))
        with open(output_path, 'ab') as f:
            f.write(self.content)
        
        # verify action changes
        old_overlay_size = self.get_overlay_size(input_path)
        new_overlay_size = self.get_overlay_size(output_path)

        logger_rew.info('old overlay size: %d, new overlay size: %d' %(old_overlay_size, new_overlay_size))
        return output_path

class ArmRD(Arm):
    def __init__(self, idx):
        super().__init__(idx)
        self.action = 'RD'
        self.name = self.action

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        pe = pefile.PE(input_path)
        segment_size = 0
        for d in pe.OPTIONAL_HEADER.DATA_DIRECTORY:
            if d.name == 'IMAGE_DIRECTORY_ENTRY_DEBUG':
                logger_rew.info('%s\t%s\t%s' %(d.name, hex(d.VirtualAddress), hex(d.Size)))
                if d.Size > 0:
                    debug_directories = pe.parse_debug_directory(d.VirtualAddress, d.Size)
                    if debug_directories:
                        for debug_directory in debug_directories:
                            debug_type = debug_directory.struct.Type
                            if debug_type == 2:
                                file_offset = debug_directory.struct.PointerToRawData
                                segment_size = debug_directory.struct.SizeOfData
                    d.VirtualAddress = 0
                    d.Size = 0

        pe.write(output_path)

        if segment_size > 0:
            # set_bytes_at_offset doesn't take effect, zero out directly.
            self.zero_out_file_content(output_path, file_offset, segment_size)

        # verify action changes
        pe = self.try_parse_pe(output_path)
        if pe:
            for d in pe.OPTIONAL_HEADER.DATA_DIRECTORY:
                if d.name == 'IMAGE_DIRECTORY_ENTRY_DEBUG':
                    logger_rew.info('%s\t%s\t%s' %(d.name, hex(d.VirtualAddress), hex(d.Size)))
        else:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)

        return output_path

class ArmRC(Arm):
    def __init__(self, idx):
        super().__init__(idx)
        self.action = 'RC'
        self.name = self.action

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        pe = pefile.PE(input_path)
        for d in pe.OPTIONAL_HEADER.DATA_DIRECTORY:
            if d.name == 'IMAGE_DIRECTORY_ENTRY_SECURITY':
                logger_rew.info('%s\t%s\t%s' %(d.name, hex(d.VirtualAddress), hex(d.Size)))
                if d.VirtualAddress > 0:
                    size_in_sig = pe.get_word_from_offset(d.VirtualAddress)
                    if size_in_sig == d.Size:
                        logger_rew.info('find sig')
                        pe.set_bytes_at_offset(d.VirtualAddress, ('\x00'*(d.Size)).encode())
                        d.VirtualAddress = 0
                        d.Size = 0

        pe.write(output_path)

        # verify action change
        pe = self.try_parse_pe(output_path)
        if pe:
            for d in pe.OPTIONAL_HEADER.DATA_DIRECTORY:
                if d.name == 'IMAGE_DIRECTORY_ENTRY_SECURITY':
                    logger_rew.info('%s\t%s\t%s' %(d.name, hex(d.VirtualAddress), hex(d.Size)))
        else:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)
        
        return output_path

class ArmCR(Arm):
    def __init__(self, idx):
        super().__init__(idx)
        self.action = 'CR'
        self.name = self.action

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        cr_path = Utils.get_randomized_folder() + Utils.get_ori_name(output_path) + '.CR'
        if os.path.exists(cr_path) == True:
            Utils.copy_file(cr_path, output_path)
            logger_rew.info('have CR file')
        else:
            logger_rew.info('do not have CR file')
            Utils.copy_file(input_path, output_path)

        # verify action change
        pe = self.try_parse_pe(output_path)
        if pe == None:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)
        
        return output_path

class ArmBC(Arm):
    def __init__(self, idx):
        super().__init__(idx)
        self.action = 'BC'
        self.name = self.action

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)
        pe = pefile.PE(input_path)
        checksum_before = pe.OPTIONAL_HEADER.CheckSum

        pe.OPTIONAL_HEADER.CheckSum = 0
        pe.write(output_path)

        # verify action changes
        pe = self.try_parse_pe(output_path)
        if pe:
            checksum_after = pe.OPTIONAL_HEADER.CheckSum
            logger_rew.info('CheckSum: before %s, after %s' %(hex(checksum_before), hex(checksum_after)))
        else:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)

        return output_path

class ArmSP(Arm):
    def __init__(self, idx, content_manager=None, section_idx=None, content=None):
        super().__init__(idx)
        self.content_manager = content_manager
        #if section_idx != None and len(content) == 1:      # todo: already add new ArmCP1
        #    self.action = 'CP1'     # special case, only CP1 init with section_idx, SP1 only set_content
        #else:
        self.action = 'SP'
        self.section_idx = section_idx
        self.content = content
        self.update_name()

    def update_name(self):
        if self.content == None:
            self.name = 'SP+Rand'
        elif len(self.content) == 1:
            self.name = 'SP+1'
        else:
            self.name = 'SP+' + hashlib.md5(self.content).hexdigest()[:8]

    def set_content(self, content):
        self.content = content
        if len(content) == 1:
            self.action = 'SP1'
        self.update_name()

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)
        pe = pefile.PE(input_path)

        # find out all available_sections
        dict_idx_to_available_size = {}
        for idx, section in enumerate(pe.sections):
            available_size = self.get_available_size_safe(pe, idx)
            if available_size > 0:
                dict_idx_to_available_size[idx] = available_size
                
        if len(dict_idx_to_available_size) == 0:
            logger_rew.info('no section has free space, return the original sample')
            Utils.copy_file(input_path, output_path)
            return output_path

        append_section_idx = self.section_idx
        # arm first use, or cannot be directly applied
        if append_section_idx == None or append_section_idx not in dict_idx_to_available_size.keys():
            append_section_idx = random.choice(list(dict_idx_to_available_size.keys()))

        available_size = dict_idx_to_available_size[append_section_idx]

        # arm first use, save for later use 
        if self.section_idx == None:
            self.section_idx = append_section_idx
        if self.content == None:
            _, _, self.content = self.content_manager.get_an_unused_content()

        append_content = self.content
        if len(append_content) != 1:            # if it's SP1, do not need to extend content
            while available_size > len(append_content):   # extend content
                append_content += self.content                    
            append_content = bytes(append_content[:available_size])

        target_section = pe.sections[append_section_idx]
        pe.set_bytes_at_offset(target_section.PointerToRawData + target_section.Misc_VirtualSize, append_content)
        logger_rew.info('section_idx: %d, content lenth: %d' %(append_section_idx, len(append_content)))
        pe.write(output_path)

        # verify action changes
        pe = self.try_parse_pe(output_path)
        if pe == None:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)

        return output_path

class ArmCP1(Arm):     # todo
    def __init__(self, idx):
        super().__init__(idx)
        self.action = 'CP1'     # special case, only CP1 init with section_idx, SP1 only set_content
        self.name = 'CP+1'

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        pe = pefile.PE(input_path)
        code_section_idx = None
        for section_idx, section in enumerate(pe.sections):
            #logger_min.info('%s: %d, %s' %(self.sname, section_idx, section.Name[:5].decode('utf-8')))
            #logger_min.info(len(section.Name[:5].decode('utf-8')))
            try:
                if section.Name[:5].decode('utf-8') == '.text':
                    available_size = self.get_available_size_safe(pe, section_idx)
                    if available_size > 0:
                        code_section_idx = section_idx
                        #logger_min.info('%s: find .text in section_idx %d' %(self.sname, code_section_idx))
                    else:
                        logger_rew.info('code section has free space')
                    break
            except Exception as e:
                #exc_type, exc_obj, exc_tb = sys.exc_info()
                #fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
                #logger_rew.error('%s %s:%s cannot parse pe' %(exc_type, fname, exc_tb.tb_lineno))
                logger_rew.error('decode section name fail')
        if code_section_idx != None:
            target_section = pe.sections[code_section_idx]
            pe.set_bytes_at_offset(target_section.PointerToRawData + target_section.Misc_VirtualSize, bytes([1]))
            pe.write(output_path)
    
            # verify action changes
            pe = self.try_parse_pe(output_path)
            if pe == None:
                logger_rew.info('pefile cannot parse, restore original file')
                Utils.copy_file(input_path, output_path)
        else:
            #logger_min.info('%s: cannot find code section' %self.sname)
            Utils.copy_file(input_path, output_path)

        return output_path

class ArmSR(Arm):
    def __init__(self, idx, content_manager=None, mutate_one_byte=None):
        super().__init__(idx)
        self.content_manager = content_manager
        self.mutate_one_byte = mutate_one_byte
        self.action = 'SR'
        self.section_idx = None
        self.new_name = None
        self.old_name = None
        self.update_name()

    def update_name(self):
        if self.mutate_one_byte:
            self.name = 'SR+1'
        elif self.new_name == None:
            self.name = 'SR+Rand'
        else:
            self.name = 'SR+' + hashlib.md5((str(self.section_idx) + self.new_name).encode()).hexdigest()[:8]

    def randomly_change_one_byte(self, old_name):
        new_name = old_name
        new_name_list = list(old_name)
        while(new_name == old_name):
            name_idx = random.randint(0, len(list(old_name))-1)
            new_name_list[name_idx] = random.choice(string.ascii_lowercase)
            new_name = "".join(new_name_list)
        return new_name

    def mutate_section_name_one_byte(self):
        self.new_name = self.randomly_change_one_byte(self.old_name)
        self.action = 'SR1'
        self.name = 'SR+1'

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        pe = pefile.PE(input_path)
        list_section_name = self.get_section_name_list(pe)
        self.print_section_names(pe)

        if self.new_name == None and self.old_name == None and self.section_idx == None:
            # arm first use
            section_idx = random.choice(range(len(list_section_name)))
            old_name = list_section_name[section_idx]
            if self.name == 'SR+1':    # if SR1, change one byte
                new_name = self.randomly_change_one_byte(old_name)
            else:                       # if SR, randomly_select_new_name
                new_name = old_name
                while new_name == old_name:
                    new_name, _, _ = self.content_manager.get_an_unused_content()
            logger_rew.info('old_name: %s, new_name: %s' %(old_name, new_name))

            # save for reuse later is succ
            self.new_name = new_name
            self.section_idx = section_idx
            self.old_name = old_name
        else:
            # reuse succ arm
            new_name = self.new_name
            if self.old_name in list_section_name:
                section_idx = list_section_name.index(self.old_name)
            elif self.section_idx >= len(list_section_name):
                section_idx = random.choice(range(len(list_section_name)))
            else:
                section_idx = self.section_idx

        pe.sections[section_idx].Name = new_name.encode()
        pe.write(output_path)

        # verify action changes
        pe = self.try_parse_pe(output_path)
        if pe:
            self.print_section_names(pe)
        else:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)

        return output_path

class ArmSA(Arm):
    def __init__(self, idx, content_manager=None, content=None):
        super().__init__(idx)
        self.content_manager = content_manager
        self.content = content
        #if content and len(content) == 1:
        #    self.action = 'SA1'
        #else:
        self.action = 'SA'
        self.section_name = None

        self.name = None
        self.update_name()
    
    def set_content(self, content):
        self.content = content
        if len(content) == 1:
            self.action = 'SA1'
        self.update_name()

    def update_name(self):
        if self.content == None:
            self.name = 'SA+Rand'
        elif len(self.content) == 1:
            self.name = 'SA+1'
        else:
            self.name = 'SA+' + hashlib.md5(self.content).hexdigest()[:8]

    def transfer(self, input_path, output_folder):
        logger_rew.info('=== %s ===' %self.action)
        output_path = self.get_output_path(output_folder, input_path)

        pe = pefile.PE(input_path)
        self.print_section_names(pe)
    
        if self.content == None:
            # SA first use
            self.section_name, _, self.content = self.content_manager.get_an_unused_content()
        if self.section_name == None:
            # SA1 first use
            self.section_name, _, _ = self.content_manager.get_an_unused_content()

        number_of_section = pe.FILE_HEADER.NumberOfSections
        last_section = number_of_section - 1
        file_alignment = pe.OPTIONAL_HEADER.FileAlignment
        section_alignment = pe.OPTIONAL_HEADER.SectionAlignment
        if last_section >= len(pe.sections):
            Utils.copy_file(input_path, output_path)
            return output_path
        new_section_header_offset = (pe.sections[number_of_section - 1].get_file_offset() + 40)
        next_header_space_content_sum = pe.get_qword_from_offset(new_section_header_offset) + \
                pe.get_qword_from_offset(new_section_header_offset + 8) + \
                pe.get_qword_from_offset(new_section_header_offset + 16) + \
                pe.get_qword_from_offset(new_section_header_offset + 24) + \
                pe.get_qword_from_offset(new_section_header_offset + 32)
        first_section_offset = pe.sections[0].PointerToRawData
        next_header_space_size = first_section_offset - new_section_header_offset
        if next_header_space_size < 40:
            logger_rew.info('no free space to add a new header before the fist section')
            Utils.copy_file(input_path, output_path)
            return output_path
        if next_header_space_content_sum != 0:
            logger_rew.info('exist hidden header or data, such as VB header')
            Utils.copy_file(input_path, output_path)
            return output_path
    
        file_size = os.path.getsize(input_path)
    
        # todo: hanlde alignment
        alignment = True
        if alignment == False:
            raw_size = 1
        else:
            raw_size = self.align(len(self.content), file_alignment)
        virtual_size = self.align(len(self.content), section_alignment)
    
        raw_offset = file_size
        #raw_offset = self.align(file_size, file_alignment)
    
        #log('1. Resize the PE file')
        Utils.copy_file(input_path, output_path)
        pe = pefile.PE(output_path)
        original_size = os.path.getsize(output_path)
        fd = open(output_path, 'a+b')
        map = mmap.mmap(fd.fileno(), 0, access=mmap.ACCESS_WRITE)
        map.resize(original_size + raw_size)
        map.close()
        fd.close()
    
        pe = pefile.PE(output_path)
        virtual_offset = self.align((pe.sections[last_section].VirtualAddress +
                            pe.sections[last_section].Misc_VirtualSize),
                            section_alignment)
    
        characteristics = 0xE0000020
        self.section_name = self.section_name + ('\x00' * (8-len(self.section_name)))
    
        #log('2. Add the New Section Header')
        hex(pe.get_qword_from_offset(new_section_header_offset))
        pe.set_bytes_at_offset(new_section_header_offset, self.section_name.encode())
        pe.set_dword_at_offset(new_section_header_offset + 8, virtual_size)
        pe.set_dword_at_offset(new_section_header_offset + 12, virtual_offset)
        pe.set_dword_at_offset(new_section_header_offset + 16, raw_size)
        pe.set_dword_at_offset(new_section_header_offset + 20, raw_offset)
        pe.set_bytes_at_offset(new_section_header_offset + 24, (12 * '\x00').encode())
        pe.set_dword_at_offset(new_section_header_offset + 36, characteristics)
    
        #log('3. Modify the Main Headers')
        pe.FILE_HEADER.NumberOfSections += 1
        pe.OPTIONAL_HEADER.SizeOfImage = virtual_size + virtual_offset
        pe.write(output_path)
    
        #log('4. Add content for the New Section')
        pe.set_bytes_at_offset(raw_offset, self.content)
        pe.write(output_path)
        
        # verify action changes
        pe = self.try_parse_pe(output_path)
        if pe:
            self.print_section_names(pe)
            logger_rew.info('new section len: %d' %len(self.content))
        else:
            logger_rew.info('pefile cannot parse, restore original file')
            Utils.copy_file(input_path, output_path)
        
        return output_path

class Bandit:
    def __init__(self):
        #self.arm_limit = get_max_working_arm_count()
        self.content_manager = ContentManager('data/benign_section_content/')

        self.samples_manager = None

        self.list_arm = []
        self.list_arm.append(ArmOA(0, content_manager=self.content_manager))
        self.list_arm.append(ArmSA(1, content_manager=self.content_manager))
        self.list_arm.append(ArmSP(2, content_manager=self.content_manager))
        self.list_arm.append(ArmSR(3, content_manager=self.content_manager))
        self.list_arm.append(ArmRD(4))
        self.list_arm.append(ArmRC(5))
        self.list_arm.append(ArmBC(6))
        self.list_arm.append(ArmCR(7))
        #self.list_arm.append(ArmOA(8, content_manager=self.content_manager, content=bytes([1])))    # OA1 todo
        #self.list_arm.append(ArmSA(9, content_manager=self.content_manager, content=bytes([1])))    # SA1 todo
        #self.list_arm.append(ArmSP(10, content_manager=self.content_manager, content=bytes([1])))   # SP1 todo
        #self.list_arm.append(ArmSR(11, content_manager=self.content_manager, mutate_one_byte=True)) # SR1 todo
        #self.list_arm.append(ArmCP1(12))                                                            # CP1 todo
        self.idx_to_ori_idx = {}

        # Bayesian UCB
        #self.counts = [0] * len(self.list_arm)
        self.c = 3
        self._as = [1] * len(self.list_arm)
        self._bs = [1] * len(self.list_arm)
        #logger_rew.info(self.list_arm)
    
    def get_next_arm(self, path, list_action):
        ## Bayesian UCB
        #list_value = [self._as[x] / float(self._as[x] + self._bs[x]) + beta.std(
        #        self._as[x], self._bs[x]) * self.c for x in range(len(self.list_arm))]
        #
        #logger_rew.info(list_value)
        #max_value = max(list_value)
        #list_max_value_idx = []
        #for idx, i in enumerate(list_value):
        #    if i == max_value:
        #        list_max_value_idx.append(idx)
        #idx = random.choice(list_max_value_idx)
        
        cr_path = Utils.get_randomized_folder() + Utils.get_ori_name(path) + '.CR'
        if len(list_action) == 0 and os.path.exists(cr_path):
            idx = 7
        else:
            while True:
                # Tompson Sampling
                samples = [np.random.beta(self._as[x], self._bs[x]) for x in range(len(self.list_arm))]
                idx = max(range(len(self.list_arm)), key=lambda x: samples[x])
                if idx not in [4,5,6,7,8,9,10,11,12]:    # RD RC BC CR OA1 SA1 SP1 CP1 only need once
                    break
                else:
                    if (idx == 4 and 'RD' not in list_action) \
                            or (idx == 5 and 'RC' not in list_action) \
                            or (idx == 6 and 'BC' not in list_action) \
                            or (idx == 7 and 'CR' not in list_action) \
                            or (idx == 8 and 'OA1' not in list_action) \
                            or (idx == 9 and 'SA1' not in list_action) \
                            or (idx == 10 and 'SP1' not in list_action) \
                            or (idx == 11 and 'CR1' not in list_action) \
                            or (idx == 12 and 'CP1' not in list_action):
                        break
                    #else:
                    #    logger_rew.info('does not need %d again for a sample with %s' %(idx, list_action))

        arm = copy.deepcopy(self.list_arm[idx])
        return arm

    def update_arm_with_reward(self, idx, reward):#, minimizer=False):
        if Utils.get_thompson_sampling() == False:
            return

        # Bayesian UCB
        # Update Gaussian posterior
        #if minimizer == False:
        self._as[idx] += reward
        self._bs[idx] += (1 - reward)
        #else:
        #    logger_rew.info('minimizer update reward!')
        #    self._as[idx] += 1
        #    #self._bs[idx] += -1
        
        if Utils.get_update_parent():
            #if child succ, give ori reward too!
            if reward == 1:
                if idx in self.idx_to_ori_idx:
                    ori_idx = self.idx_to_ori_idx[idx]
                    self._as[ori_idx] += reward
                    #self._bs[ori_idx] += (1 - reward)

    def add_new_arm(self, new_arm):
        if Utils.get_thompson_sampling() == False:
            return
        ori_idx = new_arm.idx
        new_arm.idx = len(self.list_arm)

        self.idx_to_ori_idx[new_arm.idx] = ori_idx
        
        # find existing arm
        new_arm.update_name()
        for idx, arm in enumerate(self.list_arm):
            if arm.name == new_arm.name:    # arm already exist, update existing arm
                logger_rew.info('no need to add a new arm, update existing arm')
                self._as[idx] += 1
                return

        # add a new arm, append _as _bs
        self.list_arm.append(new_arm)
        # Bayesian UCB
        #self._as.append(self._as[ori_idx])
        #self._bs.append(self._bs[ori_idx])
        self._as.append(1)
        self._bs.append(1)

class Sample:
    def __init__(self, path):
        self.path = path
        self.sname = Utils.short_name(self.path)
        self.set_current_exe_path(self.path)
        self.max_length = Utils.get_max_length()
        self.copy_time = None
        self.status = None      # queue types of which the sample is in. option: [None/pending/working/evasive/minimal/functional]
        self.scan_status = None   # file status on classifier

        self.list_applied_arm = []
        self.current_applied_arm_subset = []
        self.seq_cur_x = 0
        self.seq_cur_y = 0
        self.seq_cur_to_kept_arm = {}
        self.list_minimal_arm = []
        self.latest_minimal_path = None

    def reset(self):
        self.set_current_exe_path(self.path)
        self.copy_time = None
        self.scan_status = None
        self.list_applied_arm = []
        self.current_applied_arm_subset = []
        self.seq_cur_x = 0
        self.seq_cur_y = 0
        self.seq_cur_to_kept_arm = {}
        self.list_minimal_arm = []
        self.latest_minimal_path = None
    
    def set_current_exe_path(self, path):
        self.current_exe_path = path
        self.current_exe_md5 = self.get_md5(path)
        #logger_rew.info('set %s md5 %s' %(path, self.current_exe_md5))

    def inc_seq_cur_x(self):
        self.seq_cur_x += 1
        self.seq_cur_y = 0
    
    def inc_seq_cur_y(self):
        action = self.list_applied_arm[self.seq_cur_x].action
        list_mic_action = []
        if action in ACTION_TO_MICROACTION:
            list_mic_action = ACTION_TO_MICROACTION[action]

        if self.seq_cur_y < len(list_mic_action) - 1:
            self.seq_cur_y += 1
        else:
            self.inc_seq_cur_x()

    def get_md5(self, path):
        if os.path.exists(path) == False:
            logger_rew.info('error! file not exists: %s' %path)
            return None
        hash_md5 = hashlib.md5()
        try:
            with open(path, 'rb') as f:
                content = f.read()
                #for chunk in iter(lambda: f.read(4096), b''):
                #    logger_rew.info('3')
                hash_md5.update(content)
                #logger_rew.info(len(content))
                md5 = hash_md5.hexdigest()
            #logger_rew.info('md5: %s' %md5)
            return md5
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logger_rew.error('%s %s:%s cannot get md5' %(exc_type, fname, exc_tb.tb_lineno))
            return None

    def delete_applied_arm(self):
        # clean attributes
        #self.copy_time = None       # need?
        #self.scan_status = None       # need?

        # clean arms
        for arm in self.list_applied_arm:
            del arm
        self.list_applied_arm = []

    def delete_tmp_files(self, folder):
        logger_rew.info('delete generated tmp files in %s' %folder)
        # todo: handle file_name with '.'
        os.system('rm -f %s/%s.*' %(folder, os.path.basename(self.path)))
        self.set_current_exe_path(self.path)

    def append_arm(self, arm):
        self.list_applied_arm.append(arm)

    def copy_to_scan_folder(self, scan_folder):
        #md5 = self.get_md5(self.current_exe_path)
        self.scan_status = 'waiting'
        self.copy_time = time.time()
        Utils.copy_file(self.current_exe_path, scan_folder + os.path.basename(self.current_exe_path + '.exe'))

    def can_be_renamed(self, path):
        tmp_path = os.path.dirname(path) + '/__tmp__' + os.path.basename(path)
        try:
            if os.path.exists(path):
                os.system('mv %s %s' %(path, tmp_path))
                if os.path.exists(tmp_path):
                    os.system('mv %s %s' %(tmp_path, path))
                    if os.path.exists(path):
                        return True
        except Exception as e:
            exc_type, exc_obj, exc_tb = sys.exc_info()
            fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
            logger_rew.error('%s %s:%s cannot rename' %(exc_type, fname, exc_tb.tb_lineno))
        return False 

    def check_md5(self, filepath):
        file_md5 = self.get_md5(filepath)
        #logger_rew.info('%s: %s %s' %(self.sname, file_md5, self.current_exe_md5))
        if file_md5 and self.current_exe_md5:
            if file_md5 == self.current_exe_md5:
                return True
            else:
                logger_rew.info('%s: md5 changed. delete file.' %self.sname)
                os.system('rm -f %s' %filepath)
                return False
        return None

    def is_remain_after_threshold_time(self):
        wait_time = Utils.get_wait_time()
        existing_time = time.time() - self.copy_time
        #logger_rew.info('exising_time: %d/%d' %(existing_time, wait_time))
        if existing_time > wait_time:
            return True
        else:
            return False

    def delete_scan_folder_copy(self, scan_folder):
        os.system('rm -f %s/%s*' %(scan_folder, os.path.basename(self.path)))

    def check_scan_status(self, scan_folder):
        Utils.wait_on_stop_sign()
        #if 'ember' in Utils.get_classifier_name() or 'clamav' in Utils.get_classifier_name() or 'malconv' in Utils.get_classifier_name():       # classifiers
        if Utils.get_classifier_type() == 'model':
            scan_status = 'deleted'
            for filename in os.listdir(scan_folder):
                if Utils.get_ori_name(filename) == os.path.basename(self.path):
                    if '.benign' in filename:
                        scan_status = 'pass'
                    else:
                        scan_status = 'waiting'
                    break
            if scan_status in ['pass']:
                os.system('rm -f %s/*%s*' %(scan_folder, os.path.basename(self.path)))
            return scan_status
        else:                   # antivirus systems, need to copy file to vm
            list_file = []
            try:
                list_file = [scan_folder + x for x in os.listdir(scan_folder)]
            except Exception as e:
                exc_type, exc_obj, exc_tb = sys.exc_info()
                fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
                logger_rew.info('%s %s:%s cannot listdir' %(exc_type, fname, exc_tb.tb_lineno))
                logger_rew.info(e)
            for filepath in list_file:
                if Utils.get_ori_name(filepath) == os.path.basename(self.path):
                    md5_status = self.check_md5(filepath)
                    #logger_rew.info('%s: md5_status: %s' %(self.sname, md5_status))
                    if md5_status == None:      # cannot access file to get md5
                        scan_status = 'waiting'
                        #if self.is_remain_after_threshold_time():
                        #    scan_status = 'overtime'
                        #else:
                        #    scan_status = 'waiting'
                    elif md5_status == False:   # file md5 is changed
                        scan_status = 'deleted'
                        #if self.can_be_renamed(filepath):  # todo: check
                        #    scan_status = 'deleted'
                        #else:
                        #    if self.is_remain_after_threshold_time():  # todo: check may not need
                        #        scan_status = 'overtime'         # todo: remove overtime?
                        #    else:
                        #        scan_status = 'waiting'
                    else:                       # file md5 stay the same
                        if self.is_remain_after_threshold_time():
                            if self.can_be_renamed(filepath):
                                logger_rew.info('%s: md5 ok; time ok; rename ok' %self.sname)
                                scan_status = 'pass'
                            else:
                                logger_rew.info('%s: cannot rename' %self.sname)
                                #scan_status = 'overtime'
                                #scan_status = 'waiting'
                                scan_status = 'deleted'
                        else:
                            scan_status = 'waiting'  # time is not long enough
                    #logger_rew.info('%s: scan_status: %s' %(self.sname, scan_status))
                    if scan_status in ['pass', 'deleted']:
                        os.system('rm -f %s/*%s*' %(scan_folder, os.path.basename(self.path)))
                    return scan_status
            #logger_rew.info('%s: file not exist' %self.sname)
            scan_status = 'deleted'      # todo: check
            #logger_rew.info('%s: scan_status: %s (cannot find the file)' %(self.sname, scan_status))
            os.system('rm -f %s/*%s*' %(scan_folder, os.path.basename(self.path))) # todo: debug
            return scan_status

    def get_current_arm_list(self):
        list_arm = copy.deepcopy(self.list_applied_arm)

        # replace kept arm
        for k, v in self.seq_cur_to_kept_arm.items():
            #logger_min.info('%s: %d' %(self.sname, k))
            list_arm[k] = v

        logger_min.info('%s: list_arm: %s' %(self.sname, self.get_names_from_arm_list(list_arm)))
        #print('------------------')
        #print('%s: list_arm: %s' %(self.sname, self.get_names_from_arm_list(list_arm)))
        logger_min.info('%s: %d %d' %(self.sname, self.seq_cur_x, self.seq_cur_y))
        #print('%s: %d %d' %(self.sname, self.seq_cur_x, self.seq_cur_y))
        if self.seq_cur_x < len(self.list_applied_arm):
            action = self.list_applied_arm[self.seq_cur_x].action
            #logger_min.info('%s: %s' %(self.sname, action))
            list_mic_action = []
            if action in ACTION_TO_MICROACTION:
                list_mic_action = ACTION_TO_MICROACTION[action]
            #logger_min.info('%s %s' %(self.sname, list_mic_action))
            if self.seq_cur_y < len(list_mic_action):
                minimal_action = list_mic_action[self.seq_cur_y]
                #logger_min.info('%s: %s' %(self.sname, minimal_action))
                if minimal_action == '':          # remove current action
                    minimal_arm = None
                elif minimal_action == 'OA':      # only SA need to be minimized to OA
                    content = self.list_applied_arm[self.seq_cur_x].content
                    minimal_arm = ArmOA(0, content=content)
                elif minimal_action == 'OA1':
                    minimal_arm = ArmOA(0, content=bytes([1]))
                elif minimal_action == 'SA1':     # only SA need to be minimized to SA1
                    minimal_arm = copy.deepcopy(self.list_applied_arm[self.seq_cur_x])
                    minimal_arm.set_content(bytes([1]))
                elif minimal_action == 'SP1':     # only SP need to be minimized to SP1
                    minimal_arm = copy.deepcopy(self.list_applied_arm[self.seq_cur_x])
                    minimal_arm.set_content(bytes([1]))
                elif minimal_action == 'SR1':     # only SR need to be minimized to SR1
                    minimal_arm = copy.deepcopy(self.list_applied_arm[self.seq_cur_x])
                    minimal_arm.mutate_section_name_one_byte()
                elif minimal_action == 'CP1':     # todo: check
                    minimal_arm = ArmCP1(12)
                    #pe = pefile.PE(self.path)
                    #code_section_idx = None
                    #for section_idx, section in enumerate(pe.sections):
                    #    logger_min.info('%s: %d, %s' %(self.sname, section_idx, section.Name[:5].decode('utf-8')))
                    #    logger_min.info(len(section.Name[:5].decode('utf-8')))
                    #    if section.Name[:5].decode('utf-8') == '.text':
                    #        code_section_idx = section_idx
                    #        logger_min.info('%s: find .text in section_idx %d' %(self.sname, code_section_idx))
                    #        break
                    #if code_section_idx != None:
                    #    minimal_arm = ArmSP(2, section_idx=code_section_idx, content=bytes([1]))
                    #else:
                    #    logger_min.info('%s: cannot find code section' %self.sname)
                    #    minimal_arm = None
                else:
                    logger_min.error('%s: minimal_action unexpected: [%s]' %(self.sname, minimal_action))
                    exit()
                list_arm[self.seq_cur_x] = minimal_arm
                logger_min.info('%s: replaced one microaction: %s' %(self.sname, self.get_names_from_arm_list(list_arm)))
            self.current_applied_arm_subset = list_arm
            #logger_min.info('mic_seq_cur_to_kept_arm: %s' %self.mic_seq_cur_to_kept_arm)

    def get_names_from_arm_list(self, list_arm):
        list_arm_name = []
        for x in list_arm:
            if x:
                list_arm_name.append(x.action)
            else:
                list_arm_name.append(None)
        return list_arm_name

    def get_minimal_file(self):
        # else: decide which file is evsaive minimal exe, and copy it to minimal_folder
        if self.latest_minimal_path:                # minimal sample
            #logger_min.info('%s: latest_minimal_path %s' %(self.sname, self.latest_minimal_path))
            minimal_path = self.latest_minimal_path
        else:                                           # cannot be minimized
            list_file = [ x for x in os.listdir(evasive_folder) if os.path.basename(self.path)      in x ]
            if len(list_file) == 0:
                logger_min.error('cannot find original evasive sample')
                exit()
            minimal_path = evasive_folder + list_file[0]
            #logger_min.info('%s: cannot be minimized' %(self.sname))
        return minimal_path

    def replay_subset(self, output_folder):
        if len(self.current_applied_arm_subset) == 0:
            logger_min.error('empty replay subset')
            exit()
        input_path = self.path
        for arm in self.current_applied_arm_subset:
            if arm:
                output_path = arm.transfer(input_path, output_folder)
                input_path = output_path
                self.set_current_exe_path(output_path)
            else:
                self.set_current_exe_path(input_path)
        #logger_rew.info('output_path: %s' %output_path)

    def get_applied_actions(self):
        return self.get_names_from_arm_list(self.list_applied_arm)

class SamplesManager:
    def __init__(self, sample_folder, bandit):
        self.sample_folder = sample_folder
        self.bandit = bandit
        self.bandit.samples_manager = self
        self.cuckoo = cuckoo() if Utils.is_cuckoo_enable() else None
        self.list_sample = []   # all samples

        self.sample_concurrent_limit = Utils.get_max_working_sample_count()

        list_file = os.listdir(sample_folder)
        list_file.sort()
        for x in list_file:
            sample = Sample(self.sample_folder + x)
            self.list_sample.append(sample)

    def get_samples_with_status(self, status):
        return [ sample for sample in self.list_sample if sample.status == status ]

    def get_count_with_status(self, status):
        count = 0
        for sample in self.list_sample:
            if sample.status == status:
                count += 1
        return count

    def get_next_pending_sample(self):
        list_pending = self.get_samples_with_status('pending')
        if len(list_pending) > 0:
            for _ in range(10):  # try 10 times     # todo
                sample = random.choice(list_pending)
                count_working = self.get_count_with_status('working')
                if count_working >= self.sample_concurrent_limit:
                    logger_rew.info('concurrent sample %d is more than %d, waiting...' %(count_working, self.sample_concurrent_limit))
                    return None
                else:
                    sample.status = 'working'
                    count_working = self.get_count_with_status('working')
                    logger_rew.info('select pending sample: %s' %sample.sname)
                    logger_rew.info('count_working: %d' %count_working)
                    return sample

    def get_initial_pending_list(self):
        logger_rew.info('check whether AV can detect unchanged samples...')
        for sample in self.list_sample:
            sample.copy_to_scan_folder(rewriter_scan_folder)
            if Utils.get_classifier_type() == 'AV':
                time.sleep(0.5)
        logger_rew.info('copy to scan folder finish')
        while(True):
            for sample in self.list_sample:
                if sample.status == None:
                    scan_status = sample.check_scan_status(rewriter_scan_folder)
                    #logger_rew.info('%s: %s' %(sample.sname, scan_status))
                    #if scan_status in ['deleted', 'overtime']:
                    if scan_status == 'deleted':
                        sample.status = 'pending'
                    elif scan_status == 'pass':
                        sample.status = 'skip'
            count_all = len(self.list_sample)
            count_pending = count_skip = 0
            for sample in self.list_sample:
                if sample.status == 'pending':
                    count_pending += 1
                elif sample.status == 'skip':
                    count_skip += 1
            logger_rew.info('(%d/%d): detect %d, fail %d' %(count_pending + count_skip, count_all, count_pending, count_skip))
            time.sleep(1)
            if count_pending + count_skip == len(self.list_sample):
                break
        logger_rew.info('check finish.')
        logger_rew.info('remove remaining files.')
        os.system('rm -f %s/*' %rewriter_scan_folder)

    def update_working_list(self):
        list_working = self.get_samples_with_status('working')
        logger_rew.info('len list_working: %d' %len(list_working))
        list_fail = []
        list_succ = []
        for sample in list_working:
            # check scan_status
            scan_status = sample.check_scan_status(rewriter_scan_folder)
            #logger_rew.info('update rewriter: %s [%s]' %(sample.sname, scan_status))
            if len(sample.list_applied_arm) > 0:
                #logger_rew.info('arm list: %s' %[id(x) for x in sample.list_applied_arm])
                if scan_status == 'deleted':
                    list_fail.append(sample)
                elif scan_status == 'pass':
                    list_succ.append(sample)

        for sample in list_fail:
            last_arm = sample.list_applied_arm[-1]
            # update reward
            # todo: may need -1 after minimizer
            self.bandit.update_arm_with_reward(last_arm.idx, 0)
            #logger_rew.info('delete sample: %s' %sample.sname))
            if len(sample.list_applied_arm) >= sample.max_length:
                # restart: delete all related 1) arms 2) files on disk after max_length(10) tries
                logger_rew.info('restart: delete %s related arms and files on disk after max_length(%d) tries' %(sample.sname, sample.max_length))
                sample.delete_applied_arm()
                sample.delete_tmp_files(rewriter_output_folder)
                sample.set_current_exe_path(sample.path)
            sample.status = 'pending'

        for sample in list_succ:
            last_arm = sample.list_applied_arm[-1]
            logger_rew.info('### succ! %s' %sample.path)
            os.system('mv %s %s' %(sample.current_exe_path, evasive_folder))
            sample.delete_scan_folder_copy(rewriter_scan_folder)
            sample.scan_status = 'deleted'        # todo: need check
            sample.status = 'evasive'
        logger_rew.info('==============================================')
        logger_rew.info('list_arm: %d' %len(self.bandit.list_arm))
        for idx, arm in enumerate(self.bandit.list_arm):
            # Bayesian UCB
            logger_rew.info('%-2d %-12s a: %-3d b: %-3d' %(arm.idx, arm.name, self.bandit._as[idx], self.bandit._bs[idx]))
        logger_rew.info('==============================================')

    # Use micro actions to replace macro actions
    def minimize_evasive_sample(self):
        list_evasive = self.get_samples_with_status('evasive')
        for sample in list_evasive:
            logger_min.info('sample.scan_status: %s' %sample.scan_status)
            if sample.scan_status != 'waiting': #== 'deleted':
                if sample.seq_cur_x < len(sample.list_applied_arm):
                    sample.get_current_arm_list()
                    sample.replay_subset(minimizer_output_folder)
                    logger_min.info('%s: %s cur_idx:%s %s' %(sample.sname, sample.get_names_from_arm_list(sample.list_applied_arm), sample.seq_cur_x, sample.get_names_from_arm_list(sample.current_applied_arm_subset)))
                    sample.copy_to_scan_folder(minimizer_scan_folder)
                    #logger_min.info('%s: apply subset to generate: %s' %(sample.sname, os.path.basename(sample.current_exe_path)))

    def update_evasive_list(self, rewriter_exit):
        #for sample in self.list_sample:
        #    logger_min.info('%s: [%s]' %(sample.sname, sample.status))
        list_evasive = self.get_samples_with_status('evasive')
        #logger_min.info('len(list_evasive): %d' %len(list_evasive))
        for sample in list_evasive:
            # update scan_status
            logger_min.info('sample.scan_status: %s' %sample.scan_status)
            #if sample.scan_status in ['waiting', 'overtime']:
            if sample.scan_status  == 'waiting':
                scan_status = sample.check_scan_status(minimizer_scan_folder)
                sample.scan_status = scan_status
                if sample.scan_status == 'deleted':
                    logger_min.info('%s: [%s]' %(sample.sname, scan_status))
                    #sample.scan_status = 'deleted'
                    sample.inc_seq_cur_y()
                    # todo: add arm directly (optional)
                elif sample.scan_status == 'pass':
                    logger_min.info('%s: [%s]' %(sample.sname, scan_status))
                    logger_min.info('%s: ### minimize one action! %s' %(sample.sname, sample.current_exe_path))
                    sample.seq_cur_to_kept_arm[sample.seq_cur_x] = sample.current_applied_arm_subset[sample.seq_cur_x]
                    #logger_min.info([k, v.action] for k, v in sample.seq_cur_to_kept_arm.items())
                    sample.latest_minimal_path = sample.current_exe_path
                    sample.delete_scan_folder_copy(minimizer_scan_folder)
                    #sample.scan_status = 'deleted'
                    sample.list_minimal_arm = sample.current_applied_arm_subset
                    sample.inc_seq_cur_x()
            #logger_min.info('%s: seq_cur_x: %d len(sample.list_minimal_arm): %d' %(sample.sname, sample.seq_cur_x, len(sample.list_applied_arm)))

            if sample.seq_cur_x >= len(sample.list_applied_arm):
                logger_min.info('%s: ###### minimize finish!!!' %sample.sname)

                minimal_path = sample.get_minimal_file()
                logger_min.info('%s: copy file %s to minimal folder' %(sample.sname, minimal_path))
                Utils.copy_file(minimal_path, minimal_folder)
                sample.latest_minimal_path = minimal_folder + os.path.basename(minimal_path)
                sample.status = 'minimal'

                # find essential arms
                if len(sample.list_minimal_arm) == 0:
                    sample.list_minimal_arm = sample.list_applied_arm
                logger_min.info('list_minimal_arm: %s' %sample.get_names_from_arm_list(sample.list_minimal_arm))

                # update reward
                for arm in sample.list_minimal_arm:
                    if arm:
                        logger_min.info('%s: update_arm_with_reward %d %s %d' %(sample.sname, arm.idx, arm.name, 1))
                        self.bandit.update_arm_with_reward(arm.idx, 1)
                        if arm.idx not in [4,5,6,7,8,9,10,11,12]:   # RD RC BC CR OA1 SA1 SP1 CP1, only first arms use random content
                            logger_min.info('add new arm')
                            self.bandit.add_new_arm(arm)

                    # delete tmp files
                    sample.delete_tmp_files(rewriter_output_folder)
                    sample.delete_tmp_files(minimizer_output_folder)

    def update_minimal_list(self, rewriter_exit):
        list_minimal = self.get_samples_with_status('minimal')
        for sample in list_minimal:
            # if not submitted, submit, otherwise get existing task_id
            minimal_path = sample.get_minimal_file()
            task_id = self.cuckoo.get_task_id(minimal_path)
            #logger_min.info('task_id: %s' %task_id)

            cuckoo_status = self.cuckoo.get_task_status(task_id)
            #logger_min.info('%s: cuckoo_status: %s' %(sample.sname, cuckoo_status))

            if cuckoo_status == 'reported':
                functional = self.cuckoo.is_functional(task_id, sample.path)
                if functional:
                    # evasive and functional, copy to the final output folder
                    logger_min.info('%s: Evasive sample is functional' %sample.sname)
                    Utils.copy_file(minimal_path, functional_folder)
                    sample.status = 'functional'        ########################## this sample is done.
                else:
                    # non-functional, try again
                    logger_min.info('%s: Evasive sample is broken, add it back to pool' %sample.sname)
                    sample.reset()      # reset members
                    sample.status = 'pending'          ########################## add back to pending queue
                self.cuckoo.del_sample_and_task(minimal_path)    # clean up cuckoo
            else:
                time.sleep(1)

class ContentManager:
    def __init__(self, content_path):
        self.list_unused = []

        logger_rew.info('start to read benign section content')
        list_file = os.listdir(content_path)
        list_file.sort()
        logger_rew.info(len(list_file))
        for filename in list_file:
            name = filename.split('|')[1]
            size = int(filename.split('|')[2])
            if size < Utils.get_smallest_section_size() or size > Utils.get_largest_section_size():
                continue
            with open(content_path + filename, 'rb') as fp:
                content = fp.read()
            self.list_unused.append((name, size, content))
        logger_rew.info('content count: %d' %len(self.list_unused))
        logger_rew.info('finish')

    def get_an_unused_content(self):
        if len(self.list_unused) <= 0:
            logger_rew.error('ERROR! No more section content')
            exit()
        (name, size, content) = random.choice(self.list_unused)
        self.list_unused.remove((name, size, content))

        return name, size, content

class Rewriter:
    def __init__(self, bandit, samples_manager):
        self.data_path = 'data/'
        self.conf_path = 'conf/'
        self.randomize_path = Utils.get_randomized_folder() 
        #self.benign_section_content_path = self.data_path + 'benign_section_content/'
        self.recopy = True

        self.bandit = bandit
        self.samples_manager = samples_manager
        self.exit = False
        self.create_folders()
        
    def run_once(self):
        logger_rew.info('====================== %s =====================' %Utils.get_classifier_name())
        for sample in self.samples_manager.list_sample:
            md5 = sample.get_md5(sample.path)
            print(sample.path, md5)
            for arm in self.bandit.list_arm:
                if arm.action == 'CR':
                    continue
                output_path = arm.pull(sample)
                print(output_path)
                if os.path.exists(output_path):
                    md5_arm = sample.get_md5(output_path)
                    if md5 == md5_arm:
                        print('same arm output. rm %s' %output_path)
                        os.system('rm %s' %output_path)
                with open(sample.path, 'rb') as fp:
                    bytez = fp.read()
                    bytez_new = modify_without_breaking(bytez, [ACTION_MAP[arm.action]])
                    output_path_gym = output_path + '_gym'
                    with open(output_path_gym, 'wb') as fp_out:
                        fp_out.write(bytez_new)
                        if os.path.exists(output_path_gym):
                            md5_arm = sample.get_md5(output_path_gym)
                            if md5 == md5_arm:
                                print('same gym output. rm %s' %output_path_gym)
                                os.system('rm %s' %output_path_gym)
        print('rename \'s/\./\_/\' %s/*' %(os.path.dirname(output_path)))
        os.system('rename \'s/\./\_/\' %s/*' %(os.path.dirname(output_path)))

    def run(self):
        self.samples_manager.get_initial_pending_list()
        trial_amount = self.samples_manager.get_count_with_status('pending') * Utils.get_average_pull()
        #logger_rew.info('trial_amount: %d' %trial_amount)
        logger_rew.info('TS: %d update parent: %d' %(Utils.get_thompson_sampling(), Utils.get_update_parent()))

        total_pull_count = 0
        logger_rew.info('===========================================')
        process_count = 0
        count_skip = 0
        count_solve = 0
        count_need = 0
        while(total_pull_count < trial_amount):
            sample = self.samples_manager.get_next_pending_sample()
            if sample:
                arm = self.bandit.get_next_arm(sample.path, sample.get_applied_actions())
                output_path = arm.pull(sample)
                sample.set_current_exe_path(output_path)
                sample.append_arm(arm)
                total_pull_count += 1
                sample.copy_to_scan_folder(rewriter_scan_folder)
                process_count += 1
                if process_count % 200 == 0:
                    logger_rew.info('update rewriter working list')
                    self.samples_manager.update_working_list()
            else:
                logger_rew.info('All pending samples are processing by arms, or more than %d samples are handing at the same time' %self.samples_manager.sample_concurrent_limit)
                time.sleep(1)
                self.samples_manager.update_working_list()

            count_skip = self.samples_manager.get_count_with_status('skip')
            count_evasive = self.samples_manager.get_count_with_status('evasive')
            count_minimal = self.samples_manager.get_count_with_status('minimal')
            count_functional = self.samples_manager.get_count_with_status('functional')
            count_need = len(self.samples_manager.list_sample) - count_skip
            logger_rew.info('-----------------------------------------------')
            logger_rew.info('### [%d/%d (%.2f%%)] skip: %d evasive: %d/%d (%.2f%%) minimal: %d functioanl: %d' \
                    %(total_pull_count, trial_amount, total_pull_count/trial_amount * 100, count_skip, \
                    count_evasive + count_minimal + count_functional, count_need, \
                    ((count_evasive + count_minimal + count_functional)/count_need*100), \
                    count_minimal + count_functional, count_functional))
            logger_rew.info('-----------------------------------------------')

            if count_functional + count_skip == len(self.samples_manager.list_sample):
                break

        # wait for remaining working samples
        logger_rew.info('wait for remaining working samples')
        while True:
            count_working = self.samples_manager.get_count_with_status('working')
            count_evasive = self.samples_manager.get_count_with_status('evasive')
            count_minimal = self.samples_manager.get_count_with_status('minimal')
            if count_working + count_evasive + count_minimal == 0:
                break
            logger_rew.info('count_working: %d' %count_working)
            self.samples_manager.update_working_list()
            time.sleep(1)

        logger_rew.info('delete tmp files')
        list_pending = self.samples_manager.get_samples_with_status('pending')
        for sample in list_pending:
            sample.delete_tmp_files(rewriter_output_folder)

        logger_rew.info('%%%%%%%%%%%%%%%%%%%%%%%% Rewriter Finish %%%%%%%%%%%%%%%%%%%%%%%%')
        self.exit = True
    
    def create_folders(self):
        if Utils.get_classifier_type() == 'AV':
            cmd = 'sudo umount %s' %Utils.get_share_folder()
            print(cmd)
            os.system(cmd)
            #p = pexpect.spawn( cmd )
            #p.expect( ": " )
            #p.sendline(Utils.get_host_password())

            cmd = 'sudo mount -t cifs -o username=%s,domain=MYDOMAIN,uid=1000 //%s/share/ %s' %(Utils.get_vm_username(), Utils.get_vm_ip(), Utils.get_share_folder())
            print(cmd)
            os.system(cmd)
            #p = pexpect.spawn( cmd )
            #p.expect( ": " )
            #p.sendline(Utils.get_host_password())
            #p.expect( ": " )
            #p.sendline(Utils.get_vm_password())
            #print(Utils.get_vm_password())
            #output = p.read()

            time.sleep(3)   # manually check share folder is mounted or not

            os.system('rm -f %s/succ_action_count_update.sign' %self.conf_path)
            os.system('rm -f %s/rewriter_finish.sign' %self.conf_path)

        #os.system('mkdir -p log/')

        os.system('mkdir -p %s' %copy_tmp_folder)
        os.system('rm -fr %s/*' %copy_tmp_folder)

        os.system('mkdir -p %s' %rewriter_output_folder)
        os.system('rm -fr %s/*' %rewriter_output_folder)

        os.system('mkdir -p %s' %minimizer_output_folder)
        os.system('rm -fr %s/*' %minimizer_output_folder)

        os.system('mkdir -p %s' %rewriter_scan_folder)
        os.system('rm -fr %s/*' %rewriter_scan_folder)

        os.system('mkdir -p %s' %minimizer_scan_folder)
        os.system('rm -fr %s/*' %minimizer_scan_folder)

        os.system('mkdir -p %s' %evasive_folder)
        os.system('rm -fr %s/*' %evasive_folder)

        os.system('mkdir -p %s' %minimal_folder)
        os.system('rm -fr %s/*' %minimal_folder)

        os.system('mkdir -p %s' %functional_folder)
        os.system('rm -fr %s/*' %functional_folder)
    
class Minimizer:
    def __init__(self, samples_manager, rewriter):
        self.samples_manager = samples_manager
        self.rewriter = rewriter

    def run(self):
        while True:
            count_evasive = self.samples_manager.get_count_with_status('evasive')
            count_minimal = self.samples_manager.get_count_with_status('minimal')
            if count_evasive + count_minimal == 0:
                logger_min.info('No evasive samples, sleep...')
                time.sleep(3)
                if self.rewriter.exit:
                    logger_min.info('%%%%%%%%%%%%%%%%%%%%%%%% Minimizer Finish %%%%%%%%%%%%%%%%%%%%%%%%')
                    exit()
            else:
                self.samples_manager.minimize_evasive_sample()
                self.samples_manager.update_evasive_list(self.rewriter.exit)
                if Utils.is_cuckoo_enable():
                    self.samples_manager.update_minimal_list(self.rewriter.exit)

class cuckoo():
    def __init__(self):
        self.dict_path_to_task_id = {}
        self.headers = {'Authorization': 'Bearer %s' %Utils.get_cuckoo_token()}
        self.ori_json_folder = Utils.get_ori_json_folder()
        self.del_all_tasks()

    def get_des(self, report_json):
        list_sig = report_json['signatures']
        list_des = []
        for sig in list_sig:
            severity = sig['severity']
            description = sig['description']
            list_des.append(description)
        return list_des
    
    def get_task_id(self, minimal_path):
        if minimal_path not in self.dict_path_to_task_id:
            #logger_min.info('new sample, submit to cuckoo')
            task_id = self.submit_task(minimal_path)
        else:
            #logger_min.info('existing sample, get task_id')
            task_id = self.dict_path_to_task_id[minimal_path]
        return task_id

    def get_ori_json_path(self, sample_path):
        list_file = os.listdir(self.ori_json_folder)
        filename = os.path.basename(sample_path)
        for x in list_file:
            if filename in x:
                return self.ori_json_folder + x
    
    def get_report_by_path(self, sample_path):
        task_id = self.dict_path_to_task_id[sample_path]
        self.get_report_by_task_id(task_id)
    
    def print_name_score(self, report_json):
        filename = report_json['target']['file']['name']
        score = report_json['info']['score']
        logger_min.info('filename: %s [%s]' %(filename, score))
    
    def get_report_by_task_id(self, task_id):
        report_json = requests.get('http://localhost:8090/tasks/report/%d' %task_id, headers=self.headers).json()
        return report_json
    
    def del_all_tasks(self):
        list_task_id = self.get_task_id_list()
        for task_id in list_task_id:
            self.del_task(task_id)
    
    def del_sample_and_task(self, sample_path):
        if sample_path in self.dict_path_to_task_id:
            task_id = self.dict_path_to_task_id[sample_path]
            del self.dict_path_to_task_id[sample_path]
            self.del_task(task_id)
        else:
            logger_min.error('path not in dict_path_to_task_id, exiting...')
            exit()

    def del_task(self, task_id):
        r = requests.get('http://localhost:8090/tasks/delete/%s' %task_id, headers=self.headers)
    
    def submit_task(self, sample_path):
        with open(sample_path, 'rb') as sample:
            files = {'file': (os.path.basename(sample_path), sample)}
            r = requests.post('http://localhost:8090/tasks/create/file', headers=self.headers, files=files)
            task_id = r.json()['task_id']
        self.dict_path_to_task_id[sample_path] = task_id
        return task_id
    
    def get_tasks(self):
        r = requests.get('http://localhost:8090/tasks/list', headers=self.headers).json()
        tasks = r['tasks']
        return tasks
    
    def get_task_id_list(self):
        tasks = self.get_tasks()
        list_task_id = []
        for task in tasks:
            task_id = task['id']
            list_task_id.append(task_id)
            status = task['status']
            #logger_min.info('cuckoo task[%d]: %s ' %(task_id, status))
        return list_task_id
    
    def get_task_status(self, task_id):
        tasks = self.get_tasks()
        for task in tasks:
            cur_task_id = task['id']
            if cur_task_id == task_id:
                status = task['status']
                return status
    
    def create_output_folder(self):
        os.system('rm -fr %s' %INTERPRETER_INPUT_PATH)
        os.system('mkdir -p %s' %INTERPRETER_INPUT_PATH)
    
    def is_functional(self, task_id, path):
        report_json = self.get_report_by_task_id(task_id)
        ori_json_path = self.get_ori_json_path(path)
        with open(ori_json_path) as fp:
            ori_json = json.loads(fp.read())
        self.print_name_score(report_json)
        self.print_name_score(ori_json)
        report_des = self.get_des(report_json)
        ori_des = self.get_des(ori_json)
        if self.compare_sig_list(ori_des, report_des):
            logger_min.info('behavior is the same')
            return True
        else:
            logger_min.info('behavior is changed')
            return False

    def compare_sig_list(self, list_sig, list_sig_ori):
        encrypt = False
        for sig in list_sig:
            if 'encrypt' in sig:# or 'ansomware' in sig:
                encrypt = True
        count = 0
        for sig_ori in list_sig_ori:
            for sig in list_sig:
                if sig == sig_ori:
                    count += 1
                    break
        same_rate = float(count) / len(list_sig_ori)
        logger_min.info('len(ori), len(sig), same, rate, encrypt: %d, %d, %d, %f, %s' %(len(list_sig_ori), len(list_sig), count, same_rate, encrypt))
        if encrypt == True or len(list_sig_ori) - count <= 1 or same_rate >= 0.8:
            return True
        else:
            return False
